{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOk3oeNr6iuIZlXEBPmZ46s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_7tzxcy7pMt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyhcEyr8PQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f63b68-dfc1-40d9-cb4d-75f622b95c16"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twb6_qvo8VsB"
      },
      "source": [
        "def plot_image(image):\n",
        "  plt.figure(figsize = (2, 2))\n",
        "  plt.imshow(image, cmap = \"binary\")\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOBbl278Yiy"
      },
      "source": [
        "def plot_multiple_images(images, num_img = 10, rows = 2, cols = 5):\n",
        "  fig = plt.figure(figsize = (8, 4))\n",
        "  for ind in range(1, num_img + 1):\n",
        "    fig.add_subplot(rows, cols, ind)\n",
        "    plt.imshow(images[ind - 1], cmap = \"binary\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wtAisga9glf"
      },
      "source": [
        "X_train = train_images / 255.0\n",
        "X_train = X_train.reshape((-1, 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jpgGROl6n4l"
      },
      "source": [
        "class_names = [\"T-shirt/top\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPFOI__ytNu5"
      },
      "source": [
        "latent_size = 50\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "  keras.layers.Dense(256 * 7 * 7, input_shape = [latent_size]),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Reshape([7, 7, 256]),\n",
        "\n",
        "  keras.layers.Conv2DTranspose(128, 3, strides = 1, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "\n",
        "  keras.layers.Conv2DTranspose(64, 3, strides = 2, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "\n",
        "  keras.layers.Conv2DTranspose(32, 3, strides = 2, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "\n",
        "  keras.layers.Conv2D(1, 3, strides = 1, padding = \"same\", activation = \"sigmoid\"),\n",
        "])\n",
        "\n",
        "discriminator = keras.models.Sequential([\n",
        "  keras.layers.Conv2D(32, 3, strides = 2, padding = \"same\", input_shape = [28, 28, 1]),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Dropout(0.5),\n",
        "\n",
        "  keras.layers.Conv2D(64, 3, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Conv2D(64, 3, strides = 2, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Dropout(0.5),\n",
        "\n",
        "  keras.layers.Conv2D(128, 3, padding = \"same\"),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Dropout(0.5),\n",
        "\n",
        "  keras.layers.GlobalMaxPooling2D(),\n",
        "  keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I6_5I_LW7uT"
      },
      "source": [
        "keras.layers.Flatten(),\n",
        "  keras.layers.Dense(128),\n",
        "  keras.layers.LeakyReLU(),\n",
        "\n",
        "  keras.layers.Dense(64),\n",
        "  keras.layers.LeakyReLU(),\n",
        "  keras.layers.Dropout(0.5),"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngDCYs0vVeCm",
        "outputId": "6e8b33c6-a5f4-4db1-f508-6d6ef3370546"
      },
      "source": [
        "gan.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_3 (Sequential)    (None, 28, 28, 1)         1027329   \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 1)                 129729    \n",
            "=================================================================\n",
            "Total params: 1,157,058\n",
            "Trainable params: 1,157,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVe0DKW1Z4mQ"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "discriminator.compile(optimizer = optimizer, loss = \"binary_crossentropy\")\n",
        "gan.compile(optimizer = optimizer, loss = \"binary_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kTI3R_ZV90H"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "def train_gan(num_epochs):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch + 1} / {num_epochs}\")\n",
        "    for i in range(0, X_train.shape[0] - batch_size, batch_size):\n",
        "      #train discriminator\n",
        "      noise = tf.random.normal(shape = [batch_size, latent_size])\n",
        "      fake_images = generator(noise)\n",
        "      real_images = X_train[i : i + batch_size]\n",
        "      conc_images = np.concatenate((real_images, fake_images), axis = 0)\n",
        "      conc_labels = np.concatenate((np.ones((batch_size, 1)), np.zeros((batch_size, 1))), axis = 0)\n",
        "      discriminator.trainable = True\n",
        "      discriminator.train_on_batch(conc_images, conc_labels)\n",
        "\n",
        "      #train generator\n",
        "      noise = tf.random.normal(shape = [batch_size, latent_size])\n",
        "      labels = np.ones((batch_size, 1))\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNO_nL1aXJC",
        "outputId": "49e37dd6-ba1b-4b5b-e32b-86e4e74b8f94"
      },
      "source": [
        "train_gan(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 / 50\n",
            "Epoch: 2 / 50\n",
            "Epoch: 3 / 50\n",
            "Epoch: 4 / 50\n",
            "Epoch: 5 / 50\n",
            "Epoch: 6 / 50\n",
            "Epoch: 7 / 50\n",
            "Epoch: 8 / 50\n",
            "Epoch: 9 / 50\n",
            "Epoch: 10 / 50\n",
            "Epoch: 11 / 50\n",
            "Epoch: 12 / 50\n",
            "Epoch: 13 / 50\n",
            "Epoch: 14 / 50\n",
            "Epoch: 15 / 50\n",
            "Epoch: 16 / 50\n",
            "Epoch: 17 / 50\n",
            "Epoch: 18 / 50\n",
            "Epoch: 19 / 50\n",
            "Epoch: 20 / 50\n",
            "Epoch: 21 / 50\n",
            "Epoch: 22 / 50\n",
            "Epoch: 23 / 50\n",
            "Epoch: 24 / 50\n",
            "Epoch: 25 / 50\n",
            "Epoch: 26 / 50\n",
            "Epoch: 27 / 50\n",
            "Epoch: 28 / 50\n",
            "Epoch: 29 / 50\n",
            "Epoch: 30 / 50\n",
            "Epoch: 31 / 50\n",
            "Epoch: 32 / 50\n",
            "Epoch: 33 / 50\n",
            "Epoch: 34 / 50\n",
            "Epoch: 35 / 50\n",
            "Epoch: 36 / 50\n",
            "Epoch: 37 / 50\n",
            "Epoch: 38 / 50\n",
            "Epoch: 39 / 50\n",
            "Epoch: 40 / 50\n",
            "Epoch: 41 / 50\n",
            "Epoch: 42 / 50\n",
            "Epoch: 43 / 50\n",
            "Epoch: 44 / 50\n",
            "Epoch: 45 / 50\n",
            "Epoch: 46 / 50\n",
            "Epoch: 47 / 50\n",
            "Epoch: 48 / 50\n",
            "Epoch: 49 / 50\n",
            "Epoch: 50 / 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hSLffXUgKj2"
      },
      "source": [
        "noise = tf.random.normal([1, latent_size])\n",
        "image = generator(noise)\n",
        "plot_image(np.squeeze(image))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}